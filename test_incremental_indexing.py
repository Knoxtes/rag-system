#!/usr/bin/env python3
"""
Test Incremental Indexing System
Demonstrates how the incremental indexing works and its benefits
"""

import os
import json
import time
from incremental_indexing import IncrementalIndexingManager

def test_incremental_indexing():
    """Test the incremental indexing functionality"""
    
    print("ğŸ§ª INCREMENTAL INDEXING TEST")
    print("=" * 60)
    
    # Initialize manager
    test_tracking_file = "test_file_tracking.json"
    manager = IncrementalIndexingManager(tracking_file=test_tracking_file)
    
    print("âœ… Incremental indexing manager initialized")
    
    # Test scenario 1: All new files
    print("\nğŸ“‹ Scenario 1: All New Files")
    print("-" * 60)
    
    test_files = [
        {
            'id': 'file1_pdf',
            'name': 'company_policy.pdf',
            'modifiedTime': '2025-11-07T10:00:00Z',
            'size': '1024',
            'mimeType': 'application/pdf'
        },
        {
            'id': 'file2_img',
            'name': 'org_chart.png',
            'modifiedTime': '2025-11-07T10:30:00Z',
            'size': '2048',
            'mimeType': 'image/png'
        },
        {
            'id': 'file3_doc',
            'name': 'meeting_notes.docx',
            'modifiedTime': '2025-11-07T11:00:00Z',
            'size': '4096',
            'mimeType': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
        }
    ]
    
    categorized = manager.filter_files_for_processing(test_files, "test_collection")
    print(manager.get_incremental_summary(categorized))
    
    # Mark files as processed
    for file in test_files:
        file_info = dict(file)
        file_info['collection_name'] = 'test_collection'
        file_info['chunks_created'] = 5
        manager.mark_file_processed(file['id'], file_info)
    
    print("âœ… Files marked as processed")
    
    # Test scenario 2: One file modified, others unchanged
    print("\nğŸ“‹ Scenario 2: One File Modified")
    print("-" * 60)
    
    # Modify one file
    test_files[1]['modifiedTime'] = '2025-11-07T15:30:00Z'  # Updated timestamp
    test_files[1]['size'] = '2560'  # Updated size
    
    categorized = manager.filter_files_for_processing(test_files, "test_collection")
    print(manager.get_incremental_summary(categorized))
    
    # Test scenario 3: Add new file to existing collection
    print("\nğŸ“‹ Scenario 3: Add New File")
    print("-" * 60)
    
    test_files.append({
        'id': 'file4_new',
        'name': 'quarterly_report.xlsx',
        'modifiedTime': '2025-11-07T16:00:00Z',
        'size': '8192',
        'mimeType': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
    })
    
    categorized = manager.filter_files_for_processing(test_files, "test_collection")
    print(manager.get_incremental_summary(categorized))
    
    # Test scenario 4: All files up to date
    print("\nğŸ“‹ Scenario 4: All Files Up to Date")
    print("-" * 60)
    
    # Mark the new file as processed
    file_info = dict(test_files[-1])
    file_info['collection_name'] = 'test_collection'
    file_info['chunks_created'] = 8
    manager.mark_file_processed(test_files[-1]['id'], file_info)
    
    # Reset the modified file to original state
    test_files[1]['modifiedTime'] = '2025-11-07T10:30:00Z'
    test_files[1]['size'] = '2048'
    
    categorized = manager.filter_files_for_processing(test_files, "test_collection")
    print(manager.get_incremental_summary(categorized))
    
    # Test file tracking functionality
    print("\nğŸ“‹ File Tracking Information")
    print("-" * 60)
    
    tracked_files = manager.get_collection_files("test_collection")
    print(f"ğŸ“ Collection 'test_collection' tracks {len(tracked_files)} files:")
    
    for file_id in tracked_files:
        file_info = manager.file_registry[file_id]
        print(f"  ğŸ“„ {file_info['file_name']}")
        print(f"     Last indexed: {file_info['last_indexed']}")
        print(f"     Chunks: {file_info['chunks_created']}")
        print(f"     Modified: {file_info['modified_time']}")
    
    # Demonstrate performance benefits
    print("\nğŸ“Š Performance Benefits")
    print("-" * 60)
    
    total_files = len(test_files)
    unchanged_files = len(categorized['unchanged'])
    
    print(f"Total files in folder: {total_files}")
    print(f"Files that would be skipped: {unchanged_files}")
    print(f"Efficiency gain: {unchanged_files/total_files*100:.1f}%")
    print(f"Time savings: ~{unchanged_files * 2:.0f} minutes (estimated)")
    
    # Save tracking state
    manager.save_file_registry()
    print(f"\nâœ… File tracking saved to: {test_tracking_file}")
    
    print("\nğŸ¯ Key Benefits of Incremental Indexing:")
    print("  âœ… Only processes changed files")
    print("  âœ… Automatically detects new files") 
    print("  âœ… Removes deleted files from index")
    print("  âœ… Tracks modification timestamps")
    print("  âœ… Maintains collection integrity")
    print("  âœ… Dramatically reduces re-indexing time")
    
    # Cleanup
    if os.path.exists(test_tracking_file):
        os.remove(test_tracking_file)
        print(f"\nğŸ§¹ Cleaned up test file: {test_tracking_file}")
    
    print("\nğŸ‰ Incremental indexing test complete!")


def demonstrate_real_world_scenario():
    """Show how incremental indexing would work in practice"""
    
    print("\n\nğŸŒ REAL-WORLD USAGE SCENARIO")
    print("=" * 60)
    
    print("ğŸ“‹ Typical workflow:")
    print("1. ğŸ¢ Company has 500 documents in Google Drive folder")
    print("2. ğŸš€ Initial indexing: processes all 500 files (~16 hours)")
    print("3. ğŸ“… Next week: only 15 files were modified/added")
    print("4. âš¡ Incremental indexing: processes only 15 files (~30 minutes)")
    print("5. ğŸ¯ Result: 97% time savings!")
    
    print("\nğŸ“Š Time Comparison:")
    print("Without incremental indexing:")
    print("  - Week 1: 16 hours")
    print("  - Week 2: 16 hours (full re-index)")
    print("  - Week 3: 16 hours (full re-index)")
    print("  - Total: 48 hours")
    
    print("\nWith incremental indexing:")
    print("  - Week 1: 16 hours (initial)")
    print("  - Week 2: 30 minutes (incremental)")
    print("  - Week 3: 30 minutes (incremental)")
    print("  - Total: 17 hours")
    
    print("\nğŸ‰ Time saved: 31 hours (65% reduction)")
    
    print("\nâœ¨ Additional Benefits:")
    print("  ğŸ”„ Automatic cleanup of deleted files")
    print("  ğŸ“ Detailed tracking of what was processed")
    print("  ğŸ›¡ï¸  Reliability: no risk of missing files")
    print("  ğŸ’¡ Smart: only processes what actually changed")
    print("  ğŸ” Transparent: shows exactly what will be processed")


if __name__ == "__main__":
    test_incremental_indexing()
    demonstrate_real_world_scenario()